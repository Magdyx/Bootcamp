{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Lab Challenge Exercises Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second prompt lab in the bootcamp series, you should have completed lab 1 and the exercises follow on from those. If you completed all the exercises in Lab 1 you should find most of the exercises here straightforward\n",
    "\n",
    "This notebook is a template with all the exercises and indications of what the output should look like if you do a good job with the prompts.\n",
    "\n",
    "Before you start you should have a Python environment with the necessary libraries installed as indicated in the intro lab, you will also need a .env file with: \n",
    "- your IBM Cloud API key\n",
    "- the IBM Cloud regional URL (eg, https://us-south.ml.cloud.ibm.com)\n",
    "- the project ID associated with your WatsonX project (required by the WML Python SDK)\n",
    "\n",
    "It should take you about 30-45 min to walk through the exercises self paced\n",
    "\n",
    "Good luck and make sure you compare your answers with the model solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load credentials for Watsonx.ai (note refer to lab explaining how to do this if necessary)\n",
    "    - you should have a .env file with your IBM Cloud API key, eg API_KEY=xxx\n",
    "    - you should have a .env with the IBM Cloud regional url, eg IBM_CLOUD_URL=https://us-south.ml.cloud.ibm.com\n",
    "    - you should have a .env with the associated WatsonX project ID, eg PROJECT_ID=xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config Watsonx.ai environment\n",
    "\n",
    "api_key = \"Pdw1oZZwH40JCzOBxgNtgQsyXWROMfG2iuyiq6nhljxe\"\n",
    "ibm_cloud_url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "project_id = \"838be5fc-4383-452e-937f-4d33516b6232\"\n",
    "\n",
    "\n",
    "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "    raise Exception(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
    "else:\n",
    "    creds = {\n",
    "        \"url\": ibm_cloud_url,\n",
    "        \"apikey\": api_key \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for text generation with the [WML Python SDK](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html) for foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_watsonxai(prompts,\n",
    "                    model_name=\"google/flan-ul2\",\n",
    "                    decoding_method=\"greedy\",\n",
    "                    max_new_tokens=100,\n",
    "                    min_new_tokens=30,\n",
    "                    temperature=1.0,\n",
    "                    repetition_penalty=1.0,\n",
    "                    stop_sequences=[\"..\"]\n",
    "                    ):\n",
    "    '''\n",
    "   helper function for sending prompts and params to Watsonx.ai\n",
    "    \n",
    "    Args:  \n",
    "        prompts:list list of text prompts\n",
    "        decoding:str Watsonx.ai parameter \"sample\" or \"greedy\"\n",
    "        max_new_tok:int Watsonx.ai parameter for max new tokens/response returned\n",
    "        temperature:float Watsonx.ai parameter for temperature (range 0>2)\n",
    "        repetition_penalty:float Watsonx.ai parameter for repetition penalty (range 1.0 to 2.0)\n",
    "\n",
    "    Returns: None\n",
    "        prints response\n",
    "    '''\n",
    "\n",
    "    assert not any(map(lambda prompt: len(prompt) < 1, prompts)), \"make sure none of the prompts in the inputs prompts are empty\"\n",
    "\n",
    "    # Instantiate parameters for text generation\n",
    "    model_params = {\n",
    "        GenParams.DECODING_METHOD: decoding_method,\n",
    "        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n",
    "        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n",
    "        GenParams.RANDOM_SEED: 42,\n",
    "        GenParams.TEMPERATURE: temperature,\n",
    "        GenParams.REPETITION_PENALTY: repetition_penalty,\n",
    "        GenParams.STOP_SEQUENCES: stop_sequences\n",
    "    }\n",
    "\n",
    "\n",
    "    # Instantiate a model proxy object to send your requests\n",
    "    model = Model(\n",
    "        model_id=model_name,\n",
    "        params=model_params,\n",
    "        credentials=creds,\n",
    "        project_id=project_id)\n",
    "    #print(prompts)\n",
    "\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(model.generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_model = 'bigscience/mt0-xxl'\n",
    "flanul_model = 'google/flan-ul2'\n",
    "granite_13b_instruct_v2 = 'ibm/granite-13b-instruct-v2'\n",
    "llama2 = \"meta-llama/llama-2-70b-chat\"\n",
    "t5 = \"google/flan-t5-xxl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Review for Questions  1 - 5\n",
    "lamp_review = \"\"\"Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1) write a prompt to return the sentiment of the review\n",
    "Target sentiment = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "#Q1 Code - enter prompt and function parameters in this cell\n",
    "prompt = f\"identify the sentiment in the following product review: {lamp_review}\"\n",
    "send_to_watsonxai(prompts=[prompt],\n",
    "                  min_new_tokens= 1,\n",
    "                  max_new_tokens= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2) extract the emotions the reviewer expressed, return answer as a comma separated list\n",
    "Target emotions = satisfied, happy, cared for, great company, product!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied, happy, cared for, happy, satisfied\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],min_new_tokens=10,max_new_tokens=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3) Is the reviewer expressing anger, answer “yes” or “no” – test with your own example including anger to ensure it works in both cases.\n",
    "Target answer = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],max_new_tokens=2,min_new_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4) Extract the item purchased and the company name, return as JSON format\n",
    "Target answer = Item[lamp], Brand[Lumina]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item[lamp], Brand[Lumina]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],max_new_tokens=30,min_new_tokens=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5) Can you combine 3-6 in a single prompt and return JSON with: Sentiment (negative or positive), Anger (yes/no), Product, Company\n",
    "Target answer = Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],max_new_tokens=50,min_new_tokens=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6) summarize the following product review\n",
    "Example summary = My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Review for Questions  6 - 8\n",
    "review = \"\"\"Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it to her.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My daughter loves it! but it's a bit small for what I paid\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{review}```\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],max_new_tokens=50,min_new_tokens=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7) Summarize the same product review from the perspective of the shipping department\n",
    "Example summary = It arrived a day earlier than expected, so I got to play with it myself before I gave it  to her. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It arrived a day earlier than expected,  so I got to play with it myself before I gave it to her.\n"
     ]
    }
   ],
   "source": [
    "#concise wrt feedback shipping\n",
    "prompt = f\"\"\" \n",
    "\n",
    "read the review below, highlighted between triple backticks, and tell me about the delivery of the product\n",
    "\n",
    "Review: ```{review}```\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],max_new_tokens=50, min_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8) Summarize the review from the perspective of pricing and value\n",
    "Example summary = It's a bit small for what I paid though. I think there might be other options that are bigger for the same price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a bit small for what I paid though. I think there  might be other options that are bigger for the  same price\n"
     ]
    }
   ],
   "source": [
    "#feedback pricing works - concise\n",
    "prompt = f\"\"\"\n",
    "You should read the review below, delimited by triple \n",
    "backticks, summarize any aspects \\\n",
    "that are relevant to the price and perceived value.  \n",
    "\n",
    "Review: ```{review}```\n",
    "\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],min_new_tokens=10,max_new_tokens=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9)\tPII removal. Given the following email, write a prompt to remove the PII (eg names, emails etc) (Hint: you may need to use 1-2 shot technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Hi John,\\\n",
    "\n",
    "I'm writing to you because I noticed you recently purchased a new car. I'm a salesperson\\\n",
    "at a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new\\\n",
    "car. If you're interested, please let me know.\\\n",
    "\n",
    "Thanks,\\\n",
    "\n",
    "Jimmy Smith\\\n",
    "\n",
    "Phone: 410-805-2345\\\n",
    "Email: jimmysmith@cheapdealz.com\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint - use prompt template or manually construct the prompt with f strings (look up in documentation if unsure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi name,\n",
      "I'm writing to you because I noticed you recently purchased a new car. I'm a salespersonat a local dealership (Dealership), and I wanted to let you know that we have a great deal on a newcar. If you're interested, please let me know.\n",
      "Thanks,\n",
      "name name\n",
      "Phone: Phone\n",
      "Email: Email\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Given the following text, remove the PII (eg names, emails etc):\n",
    "\n",
    "Input: Hello, my name is Ahmed, and this is my email: ggg@xyx.com\n",
    "\n",
    "Output: Hello, my name is name, and this is my email: email\n",
    "\n",
    "Input: Hello Lucy, I wish you are fine. You know me, I'm Sandy, your friend form school. Let's connect wjen you have some time on my email: SANDY@uuu.com. Thanks Sandy Kevin.\n",
    "\n",
    "Output: Hello name, I wish you are fine. You know me, I'm name, your friend form school. Let's connect wjen you have some time on my email: email. Thanks, name name.\n",
    "\n",
    "Input: '''{email}'''\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=\"ibm-mistralai/mixtral-8x7b-instruct-v01-q\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10) Basic inference: A patients a1c level determines their diabetes status, the rules are as follows:\n",
    "\n",
    " - less than 5.7 no diabetes\n",
    " - between 5.7 and 6.5 pre-diabetes\n",
    " - greater than 6.5 diabetic.\n",
    "\n",
    "Write a prompt to return just the diabetes status from the following 3 test cases:\n",
    "\n",
    "1)\tThe patients a1c is 5.5 which is good considering his other risk factors.\n",
    "2)\tFrom the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\n",
    "3)\tShe mentioned her A1c is 8 according to her blood work about 3 years ago.\n",
    "\n",
    "Bonus 1: How could you improve the inference given the other information in the sentences?\n",
    "\n",
    "Bonus 2: how would you approach extracting the diabetes status based on patient notes without A1C values and what would you need to watch out for? (hint: maybe they are talking about family history of disease or other complications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "record1 = \"The patients a1c is 5.5 which is good considering his other risk factors.\"\n",
    "record2 = \"From the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\"\n",
    "record3 = \"She mentioned her A1c is 8 according to her blood work about 3 years ago.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no-diabetes\n"
     ]
    }
   ],
   "source": [
    "#Q1 ENTER YOUR MODEL PARAMS HERE - MAKE SURE IT WORKS WITH ALL 3 EXAMPLES ABOVE\n",
    "prompt = f\"\"\"Diabetes status is indicated by a patients a1c level. the following a1c ranges determine the diabetes status.\n",
    "First, read the a1c level from the text delimited by triple back-ticks.\n",
    "\n",
    "Next, if the a1c level is less than 5.7 then output diabetes status: no-diabetes\n",
    "if a1c level is greater than 6.5: then output diabetes status: diabetes\n",
    "if the a1c is between 5.8 and 6.4, then output diabetes status: pre-diabetes\n",
    "\n",
    "```She mentioned her A1c is 3 according to her blood work about 3 years ago.```\n",
    "\n",
    "what is the diabetes status:\"\"\"\n",
    "\n",
    "send_to_watsonxai(prompts=[prompt],max_new_tokens=10,min_new_tokens=1,model_name=\"ibm-mistralai/mixtral-8x7b-instruct-v01-q\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
